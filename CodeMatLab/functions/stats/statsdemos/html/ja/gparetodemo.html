
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- This HTML was auto-generated from MATLAB code. To make changes, update the MATLAB code and republish this document.       --><title>一般化パレート分布での裾のデータのモデル化</title><meta name="generator" content="MATLAB 7.14"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2011-11-14"><meta name="DC.source" content="gparetodemo.m"><link rel="stylesheet" type="text/css" href="../../../../matlab/helptools/private/style.css"><link rel="stylesheet" type="text/css" href="../../../../matlab/helptools/private/style_ja_JP.css"></head><body><div class="header"><div class="left"><a href="matlab:edit gparetodemo">エディターで gparetodemo.m を開く</a></div><div class="right"><a href="matlab:echodemo gparetodemo">コマンド ウィンドウで実行</a></div></div><div class="content"><h1>一般化パレート分布での裾のデータのモデル化</h1><!--introduction--><p>データへのパラメトリック分布の近似を行った場合、その結果が、高密度領域内のデータに高い精度で一致し低密度領域内のデータに低い精度で一致するモデルになることがあります。法線やスチューデントの t などの単峰型分布の場合、これらの低密度領域は、分布の「裾」と呼ばれます。モデルの近似が裾で低い理由は、定義により、モデルの選択の元になる裾にあるデータが少ないので、モードに近いデータを近似する能力に基づいてモデルが選択されることがあるからです。もう 1 つの理由は、実数データの分布が通常のパラメトリック モデルよりも複雑な場合があるからです。</p><p>しかし、多くの応用において、裾のデータの近似は主要な懸念です。一般化パレート分布 (GP) は、理論的議論に基づいて、さまざまな分布の裾をモデル化できる分布として開発されました。GP が関与する分布近似への 1 つのアプローチは、多くの観測値がある領域で非パラメトリック近似 (経験累積分布関数など) を使用し、データの裾に GP を近似することです。</p><p>この例では、この分布を最尤度によって近似するために Statistics Toolbox™ の関数を使用して GP を裾データに近似する方法を示します。</p><!--/introduction--><h2>目次</h2><div><ul><li><a href="#1">一般化パレート分布</a></li><li><a href="#3">超過データのシミュレーション</a></li><li><a href="#5">最尤を使用した分布の近似</a></li><li><a href="#7">近似の視覚的なチェック</a></li><li><a href="#9">パラメーター推定の標準誤差の計算</a></li><li><a href="#11">漸近的正規性の前提のチェック</a></li><li><a href="#13">パラメーター変換の使用</a></li></ul></div><h2>一般化パレート分布<a name="1"></a></h2><p>一般化パレート (GP) は、形状パラメーター (k) およびスケール パラメーター (sigma) でパラメーター化され、右に歪んだ分布です。k は &quot;裾の指数&quot; パラメーターとも呼ばれ、正、0、または負である場合があります。</p><pre class="codeinput">x = linspace(0,10,1000);
plot(x,gppdf(x,-.4,1),<span class="string">'-'</span>, x,gppdf(x,0,1),<span class="string">'-'</span>, x,gppdf(x,2,1),<span class="string">'-'</span>);
xlabel(<span class="string">'x / sigma'</span>); ylabel(<span class="string">'Probability density'</span>);
legend({<span class="string">'k &lt; 0'</span> <span class="string">'k = 0'</span> <span class="string">'k &gt; 0'</span>});
</pre><img vspace="5" hspace="5" src="../gparetodemo_01.png" alt=""> <p>k &lt; 0 の場合、GP は -(1/k) の上限より上の 0 確率をもちます。k &gt;= 0 の場合、GP の上限はありません。また、GP は、下限を 0 からシフトする 3 番目のしきい値パラメーターと組み合わせて使用されることがあります。ここでは、この一般性は必要ありません。</p><p>GP 分布は、指数分布 (k = 0) とパレート分布 (k &gt; 0) の両方の一般化です。GP は、大きなファミリ内でこれらの 2 つの分布を含むので、形状の範囲を連続的にとることができます。</p><h2>超過データのシミュレーション<a name="3"></a></h2><p>GP 分布は、超過を条件として直接定義できます。右裾が 0 の方向に下がる確率分布 (法線など) から始めて、その分布から個々にランダム値をサンプリングできます。しきい値を固定し、しきい値より下のすべての値を排除して残った値からしきい値を減算した場合、その結果は「超過」と呼ばれます。超過の分布は、ほぼ GP です。同様に、分布の左裾のしきい値を設定して、そのしきい値より上のすべての値を無視できます。適切な近似を取得するには、しきい値は、オリジナルの分布の裾から十分に離れていなければなりません。</p><p>結果の GP 分布の形状パラメーター k は、オリジナルの分布によって決定されます。スチューデントの t 分布のように、多項式減衰する裾をもつ分布は、正の形状パラメーターをもちます。正規分布のように、指数減衰する裾をもつ分布は、0 の形状パラメーターに相当します。ベータ分布のように、分布の裾が有限の場合は、負の形状パラメーターに相当します。</p><p>実世界における GP 分布の応用には、株収益の極値のモデル化や異常洪水のモデル化があります。この例では、5 の自由度のスチューデント t 分布から生成されたシミュレートされたデータを使用します。t 分布から 2000 の観測の最大 5% を取り、95% 分位数を減算して超過を取得します。</p><pre class="codeinput">rng(3,<span class="string">'twister'</span>);
x = trnd(5,2000,1);
q = quantile(x,.95);
y = x(x&gt;q) - q;
n = numel(y)
</pre><pre class="codeoutput">
n =

   100

</pre><h2>最尤を使用した分布の近似<a name="5"></a></h2><p>GP 分布は、0 &lt; sigma および -Inf &lt; k &lt; Inf に対して定義されます。しかし、k &lt; -1/2 の場合、最尤推定の結果の解釈は問題となります。幸い、これらのケースは、ベータや三角形のような分布からの裾の近似に該当するので、ここでは問題になりません。</p><pre class="codeinput">paramEsts = gpfit(y);
kHat      = paramEsts(1)   <span class="comment">% Tail index parameter</span>
sigmaHat  = paramEsts(2)   <span class="comment">% Scale parameter</span>
</pre><pre class="codeoutput">
kHat =

    0.0987


sigmaHat =

    0.7156

</pre><p>予期されたように、シミュレートされたデータが t 分布を使用して生成されたので、k の推定値は正です。</p><h2>近似の視覚的なチェック<a name="7"></a></h2><p>近似の程度を視覚的に評価するために、推定した GP の密度関数で重ねて、裾データのスケーリングされたヒストグラムをプロットします。ヒストグラムはスケーリングされているので、バーの高さと幅の積は 1 です。</p><pre class="codeinput">bins = 0:.25:7;
h = bar(bins,histc(y,bins)/(length(y)*.25),<span class="string">'histc'</span>);
set(h,<span class="string">'FaceColor'</span>,[.9 .9 .9]);
ygrid = linspace(0,1.1*max(y),100);
line(ygrid,gppdf(ygrid,kHat,sigmaHat));
xlim([0,6]); xlabel(<span class="string">'Exceedance'</span>); ylabel(<span class="string">'Probability Density'</span>);
</pre><img vspace="5" hspace="5" src="../gparetodemo_02.png" alt=""> <p>比較的小さいビンの幅を使用したので、ヒストグラムには多くのノイズがあります。それでも、近似密度はデータの形状に従うので、GP モデルは正しい選択であると思われます。</p><p>経験累積分布関数と近似累積分布関数を比較することもできます。</p><pre class="codeinput">[F,yi] = ecdf(y);
plot(yi,gpcdf(yi,kHat,sigmaHat),<span class="string">'-'</span>);
hold <span class="string">on</span>; stairs(yi,F,<span class="string">'r'</span>); hold <span class="string">off</span>;
legend(<span class="string">'Fitted Generalized Pareto CDF'</span>,<span class="string">'Empirical CDF'</span>,<span class="string">'location'</span>,<span class="string">'southeast'</span>);
</pre><img vspace="5" hspace="5" src="../gparetodemo_03.png" alt=""> <h2>パラメーター推定の標準誤差の計算<a name="9"></a></h2><p>推定の精度を定量化するために、最尤推定量の漸近共分散行列から計算された標準誤差を使用します。関数 <tt>gplike</tt> は、2 番目の出力として、その共分散行列への数値的近似を計算します。また、2 つの出力引数で <tt>gpfit</tt> を呼び出して、パラメーターの信頼区間を取得することもできます。</p><pre class="codeinput">[nll,acov] = gplike(paramEsts, y);
stdErr = sqrt(diag(acov))
</pre><pre class="codeoutput">
stdErr =

    0.1158
    0.1093

</pre><p>これらの標準誤差は、k の推定値の相対精度が sigma の推定値よりも顕著に低いことを示します。その標準誤差は、推定値自体に依存します。形状パラメーターは推定することが困難な場合があります。これらの標準誤差の計算では、GP モデルが正しいことが前提となること、および共分散行列への漸近的近似に対して十分なデータがあることが前提となります。</p><h2>漸近的正規性の前提のチェック<a name="11"></a></h2><p>通常、標準誤差の解釈では、同じソースのデータに対して同じ近似を繰り返すことができる場合、パラメーターの最尤推定値は正規分布とほぼ同じであることが前提になります。たとえば、信頼区間は、この前提に基づくことがあります。</p><p>しかし、正規近似は正確である場合と正確でない場合があります。この例で正規近似の程度を評価するために、ブートストラップ シミュレーションを使用できます。データから再度サンプリングして 1000 の複製データセットを生成し、それぞれに対して GP 分布を近似してすべての複製推定値を保存します。</p><pre class="codeinput">replEsts = bootstrp(1000,@gpfit,y);
</pre><p>パラメーター推定値のサンプリング分布のおおまかなチェックとして、ブートストラップ複製のヒストグラムを確認できます。</p><pre class="codeinput">subplot(2,1,1), hist(replEsts(:,1)); title(<span class="string">'Bootstrap estimates of k'</span>);
subplot(2,1,2), hist(replEsts(:,2)); title(<span class="string">'Bootstrap estimates of sigma'</span>);
</pre><img vspace="5" hspace="5" src="../gparetodemo_04.png" alt=""> <h2>パラメーター変換の使用<a name="13"></a></h2><p>sigma の推定値のヒストグラムは右に歪んでいますが、k のブートストラップ推定値のヒストグラムは若干非対象に見えます。その歪みの一般的な修復は、正規近似の精度が高いと思われる対数スケール上でパラメーターとその標準誤差を推定することです。非正規性は、直線への一致が低い点として表示されるので、Q-Q プロットはヒストグラムよりも正規性の評価に適しています。sigma の対数変換が適切かどうかを確認して、このことをチェックします。</p><pre class="codeinput">subplot(1,2,1), qqplot(replEsts(:,1)); title(<span class="string">'Bootstrap estimates of k'</span>);
subplot(1,2,2), qqplot(log(replEsts(:,2))); title(<span class="string">'Bootstrap estimates of log(sigma)'</span>);
</pre><img vspace="5" hspace="5" src="../gparetodemo_05.png" alt=""> <p>k と log(sigma) のブートストラップ推定値は正規性に十分近いと思われます。非対数スケール上の sigma の推定値の Q-Q プロットは、ヒストグラムで確認した歪みを証明します。したがって、最初に正規性の仮定の下に log(sigma) の信頼区間を取得し、次に累乗してその区間を sigma のオリジナルのスケールに変換することによって信頼性区間を構築する方が適切です。</p><p>事実、これは、関数 <tt>gpfit</tt> が背後で行う処理です。</p><pre class="codeinput">[paramEsts,paramCI] = gpfit(y);
</pre><pre class="codeinput">kHat
kCI  = paramCI(:,1)
</pre><pre class="codeoutput">
kHat =

    0.0987


kCI =

   -0.1283
    0.3258

</pre><pre class="codeinput">sigmaHat
sigmaCI  = paramCI(:,2)
</pre><pre class="codeoutput">
sigmaHat =

    0.7156


sigmaCI =

    0.5305
    0.9654

</pre><p>最尤推定に関して k の 95% 信頼区間は対称ですが、sigma の信頼区間は非対象です。これは、log(sigma) の対称 CI を変換することによって作成されたからです。</p><p class="footer">Copyright 2004-2007 The MathWorks, Inc.<br>Published with MATLAB&reg; 7.13</p><p class="footer" id="trademarks">MATLAB and Simulink are registered trademarks of The MathWorks, Inc.  Please see <a href="http://www.mathworks.com/trademarks">www.mathworks.com/trademarks</a> for a list of other trademarks owned by The MathWorks, Inc.  Other product or brand names are trademarks or registered trademarks of their respective owners.</p></div><!-- ##### SOURCE BEGIN ##### %% Modelling Tail Data with the Generalized Pareto Distribution % Fitting a parametric distribution to data sometimes results in a model % that agrees well with the data in high density regions, but poorly in % areas of low density.  For unimodal distributions, such as the normal or % Student's t, these low density regions are known as the "tails" of the % distribution. One reason why a model might fit poorly in the tails is % that by definition, there are fewer data in the tails on which to base a % choice of model, and so models are often chosen based on their ability to % fit data near the mode.  Another reason might be that the distribution of % real data is often more complicated than the usual parametric models. % % However, in many applications, fitting the data in the tail is the main % concern.  The Generalized Pareto distribution (GP) was developed as a % distribution that can model tails of a wide variety of distributions, % based on theoretical arguments.  One approach to distribution fitting % that involves the GP is to use a non-parametric fit (the empirical % cumulative distribution function, for example) in regions where there are % many observations, and to fit the GP to the tail(s) of the data. % % In this example, we'll demonstrate how to fit the GP to tail data, using % functions in the Statistics Toolbox(TM) for fitting this distribution by maximum % likelihood.  %   Copyright 2004-2011 The MathWorks, Inc. %   $Revision: 1.1.8.5 $  $Date: 2012/02/14 03:55:40 $  %% The Generalized Pareto Distribution % The Generalized Pareto (GP) is a right-skewed distribution, parameterized % with a shape parameter, k, and a scale parameter, sigma.  k is also known as % the "tail index" parameter, and can be positive, zero, or negative. x = linspace(0,10,1000); plot(x,gppdf(x,-.4,1),'-', x,gppdf(x,0,1),'-', x,gppdf(x,2,1),'-'); xlabel('x / sigma'); ylabel('Probability density'); legend({'k < 0' 'k = 0' 'k > 0'}); %% % Notice that for k < 0, the GP has zero probability above an upper limit of % -(1/k). For k >= 0, the GP has no upper limit.  Also, the GP is often used % in conjunction with a third, threshold parameter that shifts the lower limit % away from zero.  We will not need that generality here. % % The GP distribution is a generalization of both the exponential distribution % (k = 0) and the Pareto distribution (k > 0).  The GP includes those two % distributions in a larger family so that a continuous range of shapes is % possible.   %% Simulating Exceedance Data % The GP distribution can be defined constructively in terms of exceedances. % Starting with a probability distribution whose right tail drops off to zero, % such as the normal, we can sample random values independently from that % distribution.  If we fix a threshold value, throw out all the values that % are below the threshold, and subtract the threshold off of the values that % are not thrown out, the result is known as exceedences.  The distribution of % the exceedences is approximately a GP.  Similarly, we can set a threshold in % the left tail of a distribution, and ignore all values above that threshold. % The threshold must be far enough out in the tail of the original % distribution for the approximation to be reasonable. % % The original distribution determines the shape parameter, k, of the % resulting GP distribution.  Distributions whose tails fall off as a % polynomial, such as Student's t, lead to a positive shape parameter. % Distributions whose tails decrease exponentially, such as the normal, % correspond to a zero shape parameter.  Distributions with finite tails, such % as the beta, correspond to a negative shape parameter.  %% % Real-world applications for the GP distribution include modelling extremes % of stock market returns, and modelling extreme floods.  For this example, % we'll use simulated data, generated from a Student's t distribution with 5 % degrees of freedom.  We'll take the largest 5% of 2000 observations from the % t distribution, and then subtract off the 95% quantile to get exceedances. rng(3,'twister'); x = trnd(5,2000,1); q = quantile(x,.95); y = x(x>q) - q; n = numel(y)   %% Fitting the Distribution Using Maximum Likelihood % The GP distribution is defined for 0 < sigma, and -Inf < k < Inf.  However, % interpretation of the results of maximum likelihood estimation is problematic % when k < -1/2.  Fortunately, those cases correspond to fitting tails from % distributions like the beta or triangular, and so will not present a problem % here. paramEsts = gpfit(y); kHat      = paramEsts(1)   % Tail index parameter sigmaHat  = paramEsts(2)   % Scale parameter %% % As might be expected, since the simulated data were generated using a t % distribution, the estimate of k is positive.   %% Checking the Fit Visually % To visually assess how good the fit is, we'll plot a scaled histogram of % the tail data, overlayed with the density function of the GP that we've % estimated.  The histogram is scaled so that the bar heights times their % width sum to 1. bins = 0:.25:7; h = bar(bins,histc(y,bins)/(length(y)*.25),'histc'); set(h,'FaceColor',[.9 .9 .9]); ygrid = linspace(0,1.1*max(y),100); line(ygrid,gppdf(ygrid,kHat,sigmaHat)); xlim([0,6]); xlabel('Exceedance'); ylabel('Probability Density');  %% % We've used a fairly small bin width, so there is a good deal of noise in % the histogram.  Even so, the fitted density follows the shape of the % data, and so the GP model seems to be a good choice. % % We can also compare the empirical CDF to the fitted CDF. [F,yi] = ecdf(y); plot(yi,gpcdf(yi,kHat,sigmaHat),'-'); hold on; stairs(yi,F,'r'); hold off; legend('Fitted Generalized Pareto CDF','Empirical CDF','location','southeast');   %% Computing Standard Errors for the Parameter Estimates % To quantify the precision of the estimates, we'll use standard errors % computed from the asymptotic covariance matrix of the maximum likelihood % estimators.  The function |gplike| computes, as its second output, a % numerical approximation to that covariance matrix.  Alternatively, we could % have called |gpfit| with two output arguments, and it would have returned % confidence intervals for the parameters. [nll,acov] = gplike(paramEsts, y); stdErr = sqrt(diag(acov))  %% % These standard errors indicate that the relative precision of the estimate % for k is quite a bit lower that that for sigma REPLACE_WITH_DASH_DASH its standard error is on % the order of the estimate itself.  Shape parameters are often difficult to % estimate.  It's important to keep in mind that computation of these standard % errors assumed that the GP model is correct, and that we have enough data % for the asymptotic approximation to the covariance matrix to hold.   %% Checking the Asymptotic Normality Assumption % Interpretation of the standard errors usually involves assuming that, if the % same fit could be repeated many times on data that came from the same source, % the maximum likelihood estimates of the parameters would approximately % follow a normal distribution.  For example, confidence intervals are often % based this assumption. % % However, that normal approximation may or may not be a good one.  To assess % how good it is in this example, we can use a bootstrap simulation.  We will % generate 1000 replicate datasets by resampling from the data, fit a GP % distribution to each one, and save all the replicate estimates. replEsts = bootstrp(1000,@gpfit,y);  %% % As a rough check on the sampling distribution of the parameter % estimators, we can look at histograms of the bootstrap replicates. subplot(2,1,1), hist(replEsts(:,1)); title('Bootstrap estimates of k'); subplot(2,1,2), hist(replEsts(:,2)); title('Bootstrap estimates of sigma');   %% Using a Parameter Transformation % The histogram of the bootstrap estimates for k appears to be only a little % asymmetric, while that for the estimates of sigma definitely appears skewed % to the right.  A common remedy for that skewness is to estimate the % parameter and its standard error on the log scale, where a normal % approximation may be more reasonable.  A Q-Q plot is a better way to assess % normality than a histogram, because non-normality shows up as points that do % not approximately follow a straight line.  Let's check that to see if the % log transform for sigma is appropriate. subplot(1,2,1), qqplot(replEsts(:,1)); title('Bootstrap estimates of k'); subplot(1,2,2), qqplot(log(replEsts(:,2))); title('Bootstrap estimates of log(sigma)');  %% % The bootstrap estimates for k and log(sigma) appear acceptably % close to normality.  A Q-Q plot for the estimates of sigma, on the unlogged % scale, would confirm the skewness that we've already seen in the histogram. % Thus, it would be more reasonable to construct a confidence interval for % sigma by first computing one for log(sigma) under the assumption of % normality, and then exponentiating to transform that interval back to the % original scale for sigma. % % In fact, that's exactly what the function |gpfit| does behind the scenes. [paramEsts,paramCI] = gpfit(y); %% kHat kCI  = paramCI(:,1) %% sigmaHat sigmaCI  = paramCI(:,2)  %% % Notice that while the 95% confidence interval for k is symmetric about the % maximum likelihood estimate, the confidence interval for sigma is not. % That's because it was created by transforming a symmetric CI for log(sigma).   displayEndOfDemoMessage(mfilename)  ##### SOURCE END ##### --></body></html>