
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- This HTML was auto-generated from MATLAB code. To make changes, update the MATLAB code and republish this document.       --><title>部分最小二乗回帰と主成分回帰</title><meta name="generator" content="MATLAB 7.14"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2011-11-14"><meta name="DC.source" content="plspcrdemo.m"><link rel="stylesheet" type="text/css" href="../../../../matlab/helptools/private/style.css"><link rel="stylesheet" type="text/css" href="../../../../matlab/helptools/private/style_ja_JP.css"></head><body><div class="header"><div class="left"><a href="matlab:edit plspcrdemo">エディターで plspcrdemo.m を開く</a></div><div class="right"><a href="matlab:echodemo plspcrdemo">コマンド ウィンドウで実行</a></div></div><div class="content"><h1>部分最小二乗回帰と主成分回帰</h1><!--introduction--><p>この例では、部分最小二乗回帰 (PLSR) と主成分回帰 (PCR) の適用方法を示し、これら 2 つの手法の有効性について説明します。PLSR と PCR は、どちらも、高相関性または共線性のある多数の予測変数がある場合に、応答変数をモデル化するために使用する手法です。どちらの手法も、オリジナルの予測変数の線形結合として、成分と呼ばれる新しい予測変数を作成しますが、それらの成分の作成方法は異なります。PCR は、応答変数を一切考慮することなく、予測変数での観測された変動を説明する成分を作成します。一方、PLSR は応答変数を考慮するため、少ない数の成分で応答変数を近似できるモデルにつながります。特定の用途について、これが最終的により倹約的なモデルを意味するかどうかは、コンテキストによります。</p><!--/introduction--><h2>目次</h2><div><ul><li><a href="#1">データの読み込み</a></li><li><a href="#3">2 つの成分を使用したデータの近似</a></li><li><a href="#15">3 つ以上の成分を使用した近似</a></li><li><a href="#17">交差検定による成分数の選択</a></li><li><a href="#21">モデルの倹約性</a></li></ul></div><h2>データの読み込み<a name="1"></a></h2><p>401 波長でのガソリンの 60 標本のスペクトル強度と、オクタン価で構成されるデータセットを読み込みます。これらのデータは、Kalivas, John H., &quot;Two Data Sets of Near Infrared Spectra,&quot; Chemometrics and Intelligent Laboratory Systems, v.37 (1997) pp.255-259 で説明しています。</p><pre class="codeinput">load <span class="string">spectra</span>
whos <span class="string">NIR</span> <span class="string">octane</span>
</pre><pre class="codeoutput">  Name         Size              Bytes  Class     Attributes

  NIR         60x401            192480  double              
  octane      60x1                 480  double              

</pre><pre class="codeinput">[dummy,h] = sort(octane);
oldorder = get(gcf,<span class="string">'DefaultAxesColorOrder'</span>);
set(gcf,<span class="string">'DefaultAxesColorOrder'</span>,jet(60));
plot3(repmat(1:401,60,1)',repmat(octane(h),1,401)',NIR(h,:)');
set(gcf,<span class="string">'DefaultAxesColorOrder'</span>,oldorder);
xlabel(<span class="string">'Wavelength Index'</span>); ylabel(<span class="string">'Octane'</span>); axis(<span class="string">'tight'</span>);
grid <span class="string">on</span>
</pre><img vspace="5" hspace="5" src="../plspcrdemo_01.png" alt=""> <h2>2 つの成分を使用したデータの近似<a name="3"></a></h2><p>10 個の PLS 成分と 1 つの応答を使用して PLSR モデルを近似するには、関数 <tt>plsregress</tt> を使用します。</p><pre class="codeinput">X = NIR;
y = octane;
[n,p] = size(X);
[Xloadings,Yloadings,Xscores,Yscores,betaPLS10,PLSPctVar] = plsregress(<span class="keyword">...</span>
	X,y,10);
</pre><p>データを適切に近似するために、成分は 10 個も必要ないかもしれませんが、この近似からの診断を使用すると、成分数の少ないより単純なモデルを選択することができます。たとえば、成分数を簡単に選択する 1 つの方法に、応答変数で記述された分散のパーセントを成分数の関数としてプロットする方法があります。</p><pre class="codeinput">plot(1:10,cumsum(100*PLSPctVar(2,:)),<span class="string">'-bo'</span>);
xlabel(<span class="string">'Number of PLS components'</span>);
ylabel(<span class="string">'Percent Variance Explained in Y'</span>);
</pre><img vspace="5" hspace="5" src="../plspcrdemo_02.png" alt=""> <p>実際には、成分数の選択は慎重に行うことをお勧めします。たとえば、この例で後述する交差検定は広く使用される方法です。ここでは、2 つの成分を含む PLSR は観測された <tt>y</tt> の分散のほとんどを説明することが上のプロットで示されています。2 つの成分をもつモデルの近似した応答値を計算します。</p><pre class="codeinput">[Xloadings,Yloadings,Xscores,Yscores,betaPLS] = plsregress(X,y,2);
yfitPLS = [ones(n,1) X]*betaPLS;
</pre><p>次に、2 つの主成分を使用して PCR モデルを近似します。最初のステップでは関数 <tt>princomp</tt> を使用して <tt>X</tt> に対する主成分分析を実行します。この場合 PCR は、それらの 2 成分の応答変数の線形回帰にすぎません。2 つの変数の変動の量が大きく異なる場合は、標準偏差によって各変数を最初に正規化するのが普通ですが、ここではそれは行いません。</p><pre class="codeinput">[PCALoadings,PCAScores,PCAVar] = princomp(X);
betaPCR = regress(y-mean(y), PCAScores(:,1:2));
</pre><p>オリジナルのスペクトル データに関連して、PCR 結果を簡単に解釈できるようにするためには、オリジナルの中心化されていない変数の回帰係数に変換します。</p><pre class="codeinput">betaPCR = PCALoadings(:,1:2)*betaPCR;
betaPCR = [mean(y) - mean(X)*betaPCR; betaPCR];
yfitPCR = [ones(n,1) X]*betaPCR;
</pre><p>PLSR 近似と PCR 近似について、近似した応答と観測した応答をプロットします。</p><pre class="codeinput">plot(y,yfitPLS,<span class="string">'bo'</span>,y,yfitPCR,<span class="string">'r^'</span>);
xlabel(<span class="string">'Observed Response'</span>);
ylabel(<span class="string">'Fitted Response'</span>);
legend({<span class="string">'PLSR with 2 Components'</span> <span class="string">'PCR with 2 Components'</span>},  <span class="keyword">...</span>
	<span class="string">'location'</span>,<span class="string">'NW'</span>);
</pre><img vspace="5" hspace="5" src="../plspcrdemo_03.png" alt=""> <p>ある意味では、上のプロットでの比較は公平なものではありません。成分数 (2) は、2 成分をもつ PLSR モデルで応答予測が効果的に行われたことを確認してから選択したものです。PCR モデルをそれと同じ数の成分に制限する必要はありません。ただし、同じ数の成分を使った場合、<tt>y</tt> の近似は PLSR で行った方がはるかに効果的です。実際、上のプロットで近似した値の水平方向の分散を見ると、2 成分をもつ PCR は定数モデルを使用した場合とほとんど変わりません。2 つの回帰からの r 平方値がそのことを裏付けています。</p><pre class="codeinput">TSS = sum((y-mean(y)).^2);
RSS_PLS = sum((y-yfitPLS).^2);
rsquaredPLS = 1 - RSS_PLS/TSS
</pre><pre class="codeoutput">
rsquaredPLS =

    0.9466

</pre><pre class="codeinput">RSS_PCR = sum((y-yfitPCR).^2);
rsquaredPCR = 1 - RSS_PCR/TSS
</pre><pre class="codeoutput">
rsquaredPCR =

    0.1962

</pre><p>2 つのモデルの予測パワーを比較するもう 1 つの方法として、両方で 2 つの予測子に対して応答変数をプロットする方法があります。</p><pre class="codeinput">plot3(Xscores(:,1),Xscores(:,2),y-mean(y),<span class="string">'bo'</span>);
legend(<span class="string">'PLSR'</span>);
grid <span class="string">on</span>; view(-30,30);
</pre><img vspace="5" hspace="5" src="../plspcrdemo_04.png" alt=""> <p>図を対話形式で回転できないので、わかりにくいかもしれませんが、上の PLSR プロットでは、点が平面上に近接して分散しています。一方、下の PCR プロットでは、点群が示されており、線形関係があることはほとんどわかりません。</p><pre class="codeinput">plot3(PCAScores(:,1),PCAScores(:,2),y-mean(y),<span class="string">'r^'</span>);
legend(<span class="string">'PCR'</span>);
grid <span class="string">on</span>; view(-30,30);
</pre><img vspace="5" hspace="5" src="../plspcrdemo_05.png" alt=""> <p>2 つの PLS 成分は、観測された <tt>y</tt> の予測子としてははるかに優れていますが、次の図を見ると、PCR で使用された最初の 2 つの主成分と比べて、観測された <tt>X</tt> の分散が少ないことがわかります。</p><pre class="codeinput">plot(1:10,100*cumsum(PLSPctVar(1,:)),<span class="string">'b-o'</span>,1:10,  <span class="keyword">...</span>
	100*cumsum(PCAVar(1:10))/sum(PCAVar(1:10)),<span class="string">'r-^'</span>);
xlabel(<span class="string">'Number of Principal Components'</span>);
ylabel(<span class="string">'Percent Variance Explained in X'</span>);
legend({<span class="string">'PLSR'</span> <span class="string">'PCR'</span>},<span class="string">'location'</span>,<span class="string">'SE'</span>);
</pre><img vspace="5" hspace="5" src="../plspcrdemo_06.png" alt=""> <p>PCR 曲線が一様に高いという事実は、2 成分の PCR での <tt>y</tt> の近似が PLSR に劣ることを示しています。PCR では、<tt>X</tt> を最も効果的に説明するように成分を構成します。その結果、最初の 2 つの成分は、観測された <tt>y</tt> の近似で重要なデータの情報を無視します。</p><h2>3 つ以上の成分を使用した近似<a name="15"></a></h2><p>PCR に成分が追加されると共に、オリジナル データ <tt>y</tt> の近似が改善されます。これは、<tt>X</tt> における重要な予測情報のほとんどが、いつかは主成分に含まれるようになるためです。たとえば、以下の図は、10 成分を使用した場合、2 成分を使用したときと比べ、2 つの方法間の残差の差がはるかに少なくなることがわかります。</p><pre class="codeinput">yfitPLS10 = [ones(n,1) X]*betaPLS10;
betaPCR10 = regress(y-mean(y), PCAScores(:,1:10));
betaPCR10 = PCALoadings(:,1:10)*betaPCR10;
betaPCR10 = [mean(y) - mean(X)*betaPCR10; betaPCR10];
yfitPCR10 = [ones(n,1) X]*betaPCR10;
plot(y,yfitPLS10,<span class="string">'bo'</span>,y,yfitPCR10,<span class="string">'r^'</span>);
xlabel(<span class="string">'Observed Response'</span>);
ylabel(<span class="string">'Fitted Response'</span>);
legend({<span class="string">'PLSR with 10 components'</span> <span class="string">'PCR with 10 Components'</span>},  <span class="keyword">...</span>
	<span class="string">'location'</span>,<span class="string">'NW'</span>);
</pre><img vspace="5" hspace="5" src="../plspcrdemo_07.png" alt=""> <p>どちらのモデルも <tt>y</tt> をほぼ正確に近似しますが、PLSR の精度の方がわずかに上です。ただし、どちらのモデルについても 10 個の成分は任意で選択した数値です。</p><h2>交差検定による成分数の選択<a name="17"></a></h2><p>成分を複数にすることは、予測変数での将来の観測からの応答を予測する場合に、予測誤差を減らすために役立ちます。多数の成分を使用すると、現在の観測されたデータの近似の効果は上がりますが、この戦略は過適合につながります。現在のデータの近似が正確になりすぎると、他のデータのために一般化し難く、予測誤差について過度に楽観的な推定を提供するモデルが生成されます。</p><p>交差検定は、PLSR または PCR で成分を選択する方法として、統計的に優れた方法です。この方法では、モデルの近似と、予測誤差の推定に同じデータを再利用しないことで、データの過適合を防いでいます。したがって、予測誤差の推定は楽観的な下方バイアスにはなりません。</p><p><tt>plsregress</tt> には、交差検定による平均二乗予測誤差 (MSEP) を推定するオプションがあります。この場合は、10 分割交差検定を使用します。</p><pre class="codeinput">[Xl,Yl,Xs,Ys,beta,pctVar,PLSmsep] = plsregress(X,y,10,<span class="string">'CV'</span>,10);
</pre><p>PCR の場合、<tt>crossval</tt> を単純な関数と組み合わせて、PCR の誤差の二乗和を計算することで、MSEP を予測できます。ここでも 10 分割交差検定を使用します。</p><pre class="codeinput">PCRmsep = sum(crossval(@pcrsse,X,y,<span class="string">'KFold'</span>,10),1) / n;
</pre><p>PLSR の MSEP 曲線は、2 個または 3 個の成分を使用すると、最大限の効果があることを示しています。一方、PCR で同じ予測精度を実現するには 4 つの成分が必要になります。</p><pre class="codeinput">plot(0:10,PLSmsep(2,:),<span class="string">'b-o'</span>,0:10,PCRmsep,<span class="string">'r-^'</span>);
xlabel(<span class="string">'Number of components'</span>);
ylabel(<span class="string">'Estimated Mean Squared Prediction Error'</span>);
legend({<span class="string">'PLSR'</span> <span class="string">'PCR'</span>},<span class="string">'location'</span>,<span class="string">'NE'</span>);
</pre><img vspace="5" hspace="5" src="../plspcrdemo_08.png" alt=""> <p>実際、PCR の 2 番目の成分は、<i></i>モデルの予測誤差を拡大します。これは、その成分に含まれる予測変数の組み合わせと <tt>y</tt> との相関が弱いことを示しています。この理由も、PCR では <tt>y</tt> ではなく <tt>X</tt> での偏差を説明するように成分を構成するためです。</p><h2>モデルの倹約性<a name="21"></a></h2><p>PCR で 3 成分の PLSR と同じ予測精度を達成するために 4 つの成分が必要だとすると、PLSR モデルの方が倹約的ということでしょうか? その答えはモデルのどの局面を考えているかによって異なります。</p><p>PLS の重みは、PLS 成分を定義するオリジナル変数の線形組み合わせです。つまり、PLSR の各成分がオリジナル変数にどれだけ依存するか、そしてその依存方向を示します。</p><pre class="codeinput">[Xl,Yl,Xs,Ys,beta,pctVar,mse,stats] = plsregress(X,y,3);
plot(1:401,stats.W,<span class="string">'-'</span>);
xlabel(<span class="string">'Variable'</span>);
ylabel(<span class="string">'PLS Weight'</span>);
legend({<span class="string">'1st Component'</span> <span class="string">'2nd Component'</span> <span class="string">'3rd Component'</span>},  <span class="keyword">...</span>
	<span class="string">'location'</span>,<span class="string">'NW'</span>);
</pre><img vspace="5" hspace="5" src="../plspcrdemo_09.png" alt=""> <p>同様に、PCA 負荷量は、PCR の各成分がオリジナル変数にどれだけ依存するかを示します。</p><pre class="codeinput">plot(1:401,PCALoadings(:,1:4),<span class="string">'-'</span>);
xlabel(<span class="string">'Variable'</span>);
ylabel(<span class="string">'PCA Loading'</span>);
legend({<span class="string">'1st Component'</span> <span class="string">'2nd Component'</span> <span class="string">'3rd Component'</span>  <span class="keyword">...</span>
	<span class="string">'4th Component'</span>},<span class="string">'location'</span>,<span class="string">'NW'</span>);
</pre><img vspace="5" hspace="5" src="../plspcrdemo_10.png" alt=""> <p>PLSR の場合も PCR の場合も、どの変数に最大の重み付けをしているかを調べることで、物理的に意味のある解釈を与えることができる可能性があります。たとえば、これらのスペクトル データでは、ガソリンに含有される化合物に関連して、強度ピークを解釈し、特定の成分についてその重みを観測するために、少数の成分を選択することができます。この観点からは、成分の数が少ないほど解釈が簡単になります。そして、PLSR では応答を正しく予測するために必要な成分の数が少ないので、より倹約的なモデルの生成につながります。</p><p>一方、PLSR と PCR の両方で、オリジナルの各予測変数に対して 1 つの回帰係数、および 1 つの切片が生成されます。その意味では、使用した成分の数にかかわらず、どちらのモデルもすべての予測子に依存するので、どちらかがより倹約的であるとは言えません。具体的には、これらのデータでは、予測のために両方のモデルで 401 のスペクトル強度値が必要です。</p><p>しかし、最終的な目標は、オリジナルの変数セットを、1 つのサブセットに縮小し、応答を正確に予測することです。たとえば、PLS の重み、または PCA 負荷量を使用して、各成分への影響度が最も高い変数のみを選択できます。前に示したように、PCR モデル近似の一部の成分は、主に予測変数の変動を説明し、応答との相関が弱い変数に対する大きな重みを含むことができます。したがって、PCR は予測には不要な変数を維持する結果になることがあります。</p><p>この例で使用するデータについては、正確な予測のために PLSR と PCR で必要とされる成分の数の違いは大きくなく、PLS の重みと PCA の負荷量は同じ変数を選択するようです。他のデータでは必ずしもそのようにはなりません。</p><p class="footer">Copyright 2008 The MathWorks, Inc.<br>Published with MATLAB&reg; 7.13</p><p class="footer" id="trademarks">MATLAB and Simulink are registered trademarks of The MathWorks, Inc.  Please see <a href="http://www.mathworks.com/trademarks">www.mathworks.com/trademarks</a> for a list of other trademarks owned by The MathWorks, Inc.  Other product or brand names are trademarks or registered trademarks of their respective owners.</p></div><!-- ##### SOURCE BEGIN ##### %% Partial Least Squares Regression and Principal Components Regression % This example shows how to apply Partial Least Squares Regression (PLSR) % and Principal Components Regression (PCR), and discusses the % effectiveness of the two methods.  PLSR and PCR are both methods to model % a response variable when there are a large number of predictor variables, % and those predictors are highly correlated or even collinear.  Both % methods construct new predictor variables, known as components, as linear % combinations of the original predictor variables, but they construct % those components in different ways.  PCR creates components to explain % the observed variability in the predictor variables, without considering % the response variable at all. On the other hand, PLSR does take the % response variable into account, and therefore often leads to models that % are able to fit the response variable with fewer components.  Whether or % not that ultimately translates into a more parsimonious model, in terms % of its practical use, depends on the context. %  %   Copyright 2008 The MathWorks, Inc. %   $Revision: 1.1.8.5 $  $Date: 2012/02/14 03:55:45 $   %% Loading the Data % Load a data set comprising spectral intensities of 60 samples of gasoline at % 401 wavelengths, and their octane ratings.  These data are described in % Kalivas, John H., "Two Data Sets of Near Infrared Spectra," Chemometrics and % Intelligent Laboratory Systems, v.37 (1997) pp.255-259. load spectra whos NIR octane  %% [dummy,h] = sort(octane); oldorder = get(gcf,'DefaultAxesColorOrder'); set(gcf,'DefaultAxesColorOrder',jet(60)); plot3(repmat(1:401,60,1)',repmat(octane(h),1,401)',NIR(h,:)'); set(gcf,'DefaultAxesColorOrder',oldorder); xlabel('Wavelength Index'); ylabel('Octane'); axis('tight'); grid on  %% Fitting the Data with Two Components % Use the |plsregress| function to fit a PLSR model with ten PLS components % and one response. X = NIR; y = octane; [n,p] = size(X); [Xloadings,Yloadings,Xscores,Yscores,betaPLS10,PLSPctVar] = plsregress(... 	X,y,10); %% % Ten components may be more than will be needed to adequately fit the % data, but diagnostics from this fit can be used to make a choice of a % simpler model with fewer components. For example, one quick way to choose % the number of components is to plot the percent of variance explained in % the response variable as a function of the number of components. plot(1:10,cumsum(100*PLSPctVar(2,:)),'-bo'); xlabel('Number of PLS components'); ylabel('Percent Variance Explained in Y'); %% % In practice, more care would probably be advisable in choosing the number % of components.  Cross-validation, for instance, is a widely-used method % that will be illustrated later in this example.  For now, the above plot % suggests that PLSR with two components explains most of the variance in % the observed |y|.  Compute the fitted response values for the % two-component model. [Xloadings,Yloadings,Xscores,Yscores,betaPLS] = plsregress(X,y,2); yfitPLS = [ones(n,1) X]*betaPLS;  %% % Next, fit a PCR model with two principal components.  The first step is % to perform Principal Components Analysis on |X|, using the |princomp| % function, and retaining two principal components. PCR is then just a % linear regression of the response variable on those two components.  It % often makes sense to normalize each variable first by its standard % deviation when the variables have very different amounts of variability, % however, that is not done here. [PCALoadings,PCAScores,PCAVar] = princomp(X); betaPCR = regress(y-mean(y), PCAScores(:,1:2)); %% % To make the PCR results easier to interpret in terms of the original % spectral data, transform to regression coefficients for the original, % uncentered variables. betaPCR = PCALoadings(:,1:2)*betaPCR; betaPCR = [mean(y) - mean(X)*betaPCR; betaPCR]; yfitPCR = [ones(n,1) X]*betaPCR;  %% % Plot fitted vs. observed response for the PLSR and PCR fits. plot(y,yfitPLS,'bo',y,yfitPCR,'r^'); xlabel('Observed Response'); ylabel('Fitted Response'); legend({'PLSR with 2 Components' 'PCR with 2 Components'},  ... 	'location','NW'); %% % In a sense, the comparison in the plot above is not a fair one REPLACE_WITH_DASH_DASH the % number of components (two) was chosen by looking at how well a % two-component PLSR model predicted the response, and there's no reason % why the PCR model should be restricted to that same number of components. % With the same number of components, however, PLSR does a much better job % at fitting |y|.  In fact, looking at the horizontal scatter of fitted % values in the plot above, PCR with two components is hardly better than % using a constant model.  The r-squared values from the two regressions % confirm that. TSS = sum((y-mean(y)).^2); RSS_PLS = sum((y-yfitPLS).^2); rsquaredPLS = 1 - RSS_PLS/TSS %% RSS_PCR = sum((y-yfitPCR).^2); rsquaredPCR = 1 - RSS_PCR/TSS  %% % Another way to compare the predictive power of the two models is to plot the % response variable against the two predictors in both cases. plot3(Xscores(:,1),Xscores(:,2),y-mean(y),'bo'); legend('PLSR'); grid on; view(-30,30); %% % It's a little hard to see without being able to interactively rotate the % figure, but the PLSR plot above shows points closely scattered about a plane. % On the other hand, the PCR plot below shows a cloud of points with little % indication of a linear relationship. plot3(PCAScores(:,1),PCAScores(:,2),y-mean(y),'r^'); legend('PCR'); grid on; view(-30,30);  %% % Notice that while the two PLS components are much better predictors of % the observed |y|, the following figure demonstrates that they explain % somewhat less variance in the observed |X| than the first two principal % components used in the PCR. plot(1:10,100*cumsum(PLSPctVar(1,:)),'b-o',1:10,  ... 	100*cumsum(PCAVar(1:10))/sum(PCAVar(1:10)),'r-^'); xlabel('Number of Principal Components'); ylabel('Percent Variance Explained in X'); legend({'PLSR' 'PCR'},'location','SE'); %% % The fact that the PCR curve is uniformly higher suggests why PCR with two % components does such a poor job, relative to PLSR, in fitting |y|.  PCR % constructs components to best explain |X|, and as a result, those first % two components ignore the information in the data that is important in % fitting the observed |y|.   %% Fitting with More Components % As more components are added in PCR, it will necessarily do a better job % of fitting the original data |y|, simply because at some point most of the % important predictive information in |X| will be present in the principal % components.  For example, the following figure demonstrates that the % difference in residuals for the two methods is much less dramatic when % using ten components than it was for two components. yfitPLS10 = [ones(n,1) X]*betaPLS10; betaPCR10 = regress(y-mean(y), PCAScores(:,1:10)); betaPCR10 = PCALoadings(:,1:10)*betaPCR10; betaPCR10 = [mean(y) - mean(X)*betaPCR10; betaPCR10]; yfitPCR10 = [ones(n,1) X]*betaPCR10; plot(y,yfitPLS10,'bo',y,yfitPCR10,'r^'); xlabel('Observed Response'); ylabel('Fitted Response'); legend({'PLSR with 10 components' 'PCR with 10 Components'},  ... 	'location','NW'); %% % Both models fit |y| fairly accurately, although PLSR still makes a % slightly more accurate fit.  However, ten components is still an % arbitrarily-chosen number for either model.   %% Choosing the Number of Components with Cross-Validation % It's often useful to choose the number of components to minimize the % expected error when predicting the response from future observations on % the predictor variables.  Simply using a large number of components will % do a good job in fitting the current observed data, but is a strategy % that leads to overfitting.  Fitting the current data too well results in % a model that does not generalize well to other data, and gives an % overly-optimistic estimate of the expected error. % % Cross-validation is a more statistically sound method for choosing the % number of components in either PLSR or PCR.  It avoids overfitting data % by not reusing the same data to both fit a model and to estimate % prediction error. Thus, the estimate of prediction error is not % optimistically biased downwards. % % |plsregress| has an option to estimate the mean squared prediction error % (MSEP) by cross-validation, in this case using 10-fold C-V. [Xl,Yl,Xs,Ys,beta,pctVar,PLSmsep] = plsregress(X,y,10,'CV',10); %% % For PCR, |crossval| combined with a simple function to compute the sum of % squared errors for PCR, can estimate the MSEP, again using 10-fold % cross-validation. PCRmsep = sum(crossval(@pcrsse,X,y,'KFold',10),1) / n;  %% % The MSEP curve for PLSR indicates that two or three components does about % as good a job as possible.  On the other hand, PCR needs four components % to get the same prediction accuracy. plot(0:10,PLSmsep(2,:),'b-o',0:10,PCRmsep,'r-^'); xlabel('Number of components'); ylabel('Estimated Mean Squared Prediction Error'); legend({'PLSR' 'PCR'},'location','NE'); %% % In fact, the second component in PCR _increases_ the prediction error % of the model, suggesting that the combination of predictor variables % contained in that component is not strongly correlated with |y|.  Again, % that's because PCR constructs components to explain variation in |X|, not % |y|.   %% Model Parsimony % So if PCR requires four components to get the same prediction accuracy as % PLSR with three components, is the PLSR model more parsimonious?  That % depends on what aspect of the model you consider. % % The PLS weights are the linear combinations of the original variables % that define the PLS components, i.e., they describe how strongly each % component in the PLSR depends on the original variables, and in what % direction. [Xl,Yl,Xs,Ys,beta,pctVar,mse,stats] = plsregress(X,y,3); plot(1:401,stats.W,'-'); xlabel('Variable'); ylabel('PLS Weight'); legend({'1st Component' '2nd Component' '3rd Component'},  ... 	'location','NW'); %% % Similarly, the PCA loadings describe how strongly each component in the PCR % depends on the original variables. plot(1:401,PCALoadings(:,1:4),'-'); xlabel('Variable'); ylabel('PCA Loading'); legend({'1st Component' '2nd Component' '3rd Component'  ... 	'4th Component'},'location','NW');  %% % For either PLSR or PCR, it may be that each component can be given a % physically meaningful interpretation by inspecting which variables it % weights most heavily.  For instance, with these spectral data it may be % possible to interpret intensity peaks in terms of compounds present in % the gasoline, and then to observe that weights for a particular component % pick out a small number of those compounds.  From that perspective, fewer % components are simpler to interpret, and because PLSR often requires % fewer components to predict the response adequately, it leads to more % parsimonious models. %  % On the other hand, both PLSR and PCR result in one regression coefficient % for each of the original predictor variables, plus an intercept.  In that % sense, neither is more parsimonious, because regardless of how many % components are used, both models depend on all predictors.  More % concretely, for these data, both models need 401 spectral intensity % values in order to make a prediction. % % However, the ultimate goal may to reduce the original set of variables to % a smaller subset still able to predict the response accurately.  For % example, it may be possible to use the PLS weights or the PCA loadings to % select only those variables that contribute most to each component.  As % demonstrated earlier, some components from a PCR model fit may serve % primarily to describe the variation in the predictor variables, and may % include large weights for variables that are not strongly correlated with % the response. Thus, PCR can lead to retaining variables that are % unnecessary for prediction. % % For the data used in this example, the difference in the number of % components needed by PLSR and PCR for accurate prediction is not great, % and the PLS weights and PCA loadings seem to pick out the same variables. % That may not be true for other data.   displayEndOfDemoMessage(mfilename) ##### SOURCE END ##### --></body></html>